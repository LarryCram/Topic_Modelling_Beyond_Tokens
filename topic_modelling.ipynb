{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üó£Ô∏è Topic Modelling: Going Beyond¬†Tokens Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying keyword extraction techniques alongside topic modelling in order to assign topics with meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "from rake_nltk import Rake\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import collections\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovation in Database Management: Computer Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High performance prime field multiplication fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enchanted scissors: a scissor interface for su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detection of channel degradation attack by Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pinning a Complex Network through the Betweenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analysis and Design of Memoryless Interconnect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dynamic bluescreens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Quantitative Assured Forwarding Service.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automatic sanitization of social network data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A &amp;#916;&amp;#931; IR-UWB radar with sub-mm rangin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Innovation in Database Management: Computer Sc...\n",
       "1  High performance prime field multiplication fo...\n",
       "2  enchanted scissors: a scissor interface for su...\n",
       "3  Detection of channel degradation attack by Int...\n",
       "4  Pinning a Complex Network through the Betweenn...\n",
       "5  Analysis and Design of Memoryless Interconnect...\n",
       "6                               Dynamic bluescreens.\n",
       "7         A Quantitative Assured Forwarding Service.\n",
       "8  Automatic sanitization of social network data ...\n",
       "9  A &#916;&#931; IR-UWB radar with sub-mm rangin..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "df = pd.read_csv('research_paper_titles.csv', header = None)\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovation in Database Management: Computer Sc...</td>\n",
       "      <td>innovation in database management computer sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High performance prime field multiplication fo...</td>\n",
       "      <td>high performance prime field multiplication fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enchanted scissors: a scissor interface for su...</td>\n",
       "      <td>enchanted scissors a scissor interface for sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detection of channel degradation attack by Int...</td>\n",
       "      <td>detection of channel degradation attack by int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pinning a Complex Network through the Betweenn...</td>\n",
       "      <td>pinning a complex network through the betweenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analysis and Design of Memoryless Interconnect...</td>\n",
       "      <td>analysis and design of memoryless interconnect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dynamic bluescreens.</td>\n",
       "      <td>dynamic bluescreens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Quantitative Assured Forwarding Service.</td>\n",
       "      <td>a quantitative assured forwarding service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automatic sanitization of social network data ...</td>\n",
       "      <td>automatic sanitization of social network data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A &amp;#916;&amp;#931; IR-UWB radar with sub-mm rangin...</td>\n",
       "      <td>a 916 931 ir uwb radar with sub mm ranging cap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Innovation in Database Management: Computer Sc...   \n",
       "1  High performance prime field multiplication fo...   \n",
       "2  enchanted scissors: a scissor interface for su...   \n",
       "3  Detection of channel degradation attack by Int...   \n",
       "4  Pinning a Complex Network through the Betweenn...   \n",
       "5  Analysis and Design of Memoryless Interconnect...   \n",
       "6                               Dynamic bluescreens.   \n",
       "7         A Quantitative Assured Forwarding Service.   \n",
       "8  Automatic sanitization of social network data ...   \n",
       "9  A &#916;&#931; IR-UWB radar with sub-mm rangin...   \n",
       "\n",
       "                                                   1  \n",
       "0  innovation in database management computer sci...  \n",
       "1  high performance prime field multiplication fo...  \n",
       "2  enchanted scissors a scissor interface for sup...  \n",
       "3  detection of channel degradation attack by int...  \n",
       "4  pinning a complex network through the betweenn...  \n",
       "5  analysis and design of memoryless interconnect...  \n",
       "6                                dynamic bluescreens  \n",
       "7          a quantitative assured forwarding service  \n",
       "8  automatic sanitization of social network data ...  \n",
       "9  a 916 931 ir uwb radar with sub mm ranging cap...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# case text as lowercase, remove punctuation, remove extra whitespace in string and on both sides of string\n",
    "\n",
    "df[1] = df[0].str.lower().str.replace('[^\\w\\s]', ' ').str.replace(' +', ' ').str.strip()\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovation in Database Management: Computer Sc...</td>\n",
       "      <td>[innovation, in, database, management, compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High performance prime field multiplication fo...</td>\n",
       "      <td>[high, performance, prime, field, multiplicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enchanted scissors: a scissor interface for su...</td>\n",
       "      <td>[enchanted, scissors, a, scissor, interface, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detection of channel degradation attack by Int...</td>\n",
       "      <td>[detection, of, channel, degradation, attack, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pinning a Complex Network through the Betweenn...</td>\n",
       "      <td>[pinning, a, complex, network, through, the, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analysis and Design of Memoryless Interconnect...</td>\n",
       "      <td>[analysis, and, design, of, memoryless, interc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dynamic bluescreens.</td>\n",
       "      <td>[dynamic, bluescreens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Quantitative Assured Forwarding Service.</td>\n",
       "      <td>[a, quantitative, assured, forwarding, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automatic sanitization of social network data ...</td>\n",
       "      <td>[automatic, sanitization, of, social, network,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A &amp;#916;&amp;#931; IR-UWB radar with sub-mm rangin...</td>\n",
       "      <td>[a, 916, 931, ir, uwb, radar, with, sub, mm, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Innovation in Database Management: Computer Sc...   \n",
       "1  High performance prime field multiplication fo...   \n",
       "2  enchanted scissors: a scissor interface for su...   \n",
       "3  Detection of channel degradation attack by Int...   \n",
       "4  Pinning a Complex Network through the Betweenn...   \n",
       "5  Analysis and Design of Memoryless Interconnect...   \n",
       "6                               Dynamic bluescreens.   \n",
       "7         A Quantitative Assured Forwarding Service.   \n",
       "8  Automatic sanitization of social network data ...   \n",
       "9  A &#916;&#931; IR-UWB radar with sub-mm rangin...   \n",
       "\n",
       "                                                   1  \n",
       "0  [innovation, in, database, management, compute...  \n",
       "1  [high, performance, prime, field, multiplicati...  \n",
       "2  [enchanted, scissors, a, scissor, interface, f...  \n",
       "3  [detection, of, channel, degradation, attack, ...  \n",
       "4  [pinning, a, complex, network, through, the, b...  \n",
       "5  [analysis, and, design, of, memoryless, interc...  \n",
       "6                             [dynamic, bluescreens]  \n",
       "7    [a, quantitative, assured, forwarding, service]  \n",
       "8  [automatic, sanitization, of, social, network,...  \n",
       "9  [a, 916, 931, ir, uwb, radar, with, sub, mm, r...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenise string\n",
    "\n",
    "df[1] = df.apply(lambda row: nltk.word_tokenize(row[1]), axis=1)\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovation in Database Management: Computer Sc...</td>\n",
       "      <td>[innovation, database, management, computer, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High performance prime field multiplication fo...</td>\n",
       "      <td>[high, performance, prime, field, multiplicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enchanted scissors: a scissor interface for su...</td>\n",
       "      <td>[enchanted, scissors, scissor, interface, supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detection of channel degradation attack by Int...</td>\n",
       "      <td>[detection, channel, degradation, attack, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pinning a Complex Network through the Betweenn...</td>\n",
       "      <td>[pinning, complex, network, betweenness, centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analysis and Design of Memoryless Interconnect...</td>\n",
       "      <td>[analysis, design, memoryless, interconnect, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dynamic bluescreens.</td>\n",
       "      <td>[dynamic, bluescreens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Quantitative Assured Forwarding Service.</td>\n",
       "      <td>[quantitative, assured, forwarding, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automatic sanitization of social network data ...</td>\n",
       "      <td>[automatic, sanitization, social, network, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A &amp;#916;&amp;#931; IR-UWB radar with sub-mm rangin...</td>\n",
       "      <td>[916, 931, ir, uwb, radar, sub, mm, ranging, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Innovation in Database Management: Computer Sc...   \n",
       "1  High performance prime field multiplication fo...   \n",
       "2  enchanted scissors: a scissor interface for su...   \n",
       "3  Detection of channel degradation attack by Int...   \n",
       "4  Pinning a Complex Network through the Betweenn...   \n",
       "5  Analysis and Design of Memoryless Interconnect...   \n",
       "6                               Dynamic bluescreens.   \n",
       "7         A Quantitative Assured Forwarding Service.   \n",
       "8  Automatic sanitization of social network data ...   \n",
       "9  A &#916;&#931; IR-UWB radar with sub-mm rangin...   \n",
       "\n",
       "                                                   1  \n",
       "0  [innovation, database, management, computer, s...  \n",
       "1  [high, performance, prime, field, multiplicati...  \n",
       "2  [enchanted, scissors, scissor, interface, supp...  \n",
       "3  [detection, channel, degradation, attack, inte...  \n",
       "4  [pinning, complex, network, betweenness, centr...  \n",
       "5  [analysis, design, memoryless, interconnect, e...  \n",
       "6                             [dynamic, bluescreens]  \n",
       "7       [quantitative, assured, forwarding, service]  \n",
       "8  [automatic, sanitization, social, network, dat...  \n",
       "9  [916, 931, ir, uwb, radar, sub, mm, ranging, c...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initiate stopwords from nltk\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# add additional missing terms\n",
    "\n",
    "stop_words.extend(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m','n','o','p','q','r','s','t', 'u', 'v', 'w', 'x', 'y', 'z', \"about\", \"across\", \"after\", \"all\", \"also\", \"an\", \"and\", \"another\", \"added\",\n",
    "\"any\", \"are\", \"as\", \"at\", \"basically\", \"be\", \"because\", 'become', \"been\", \"before\", \"being\", \"between\",\"both\", \"but\", \"by\",\"came\",\"can\",\"come\",\"could\",\"did\",\"do\",\"does\",\"each\",\"else\",\"every\",\"either\",\"especially\", \"for\",\"from\",\"get\",\"given\",\"gets\",\n",
    "'give','gives',\"got\",\"goes\",\"had\",\"has\",\"have\",\"he\",\"her\",\"here\",\"him\",\"himself\",\"his\",\"how\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"lands\",\"like\",\"make\",\"making\", \"made\", \"many\",\"may\",\"me\",\"might\",\"more\",\"most\",\"much\",\"must\",\"my\",\"never\",\"provide\", \n",
    "\"provides\", \"perhaps\",\"no\",\"now\",\"of\",\"on\",\"only\",\"or\",\"other\", \"our\",\"out\",\"over\",\"re\",\"said\",\"same\",\"see\",\"should\",\"since\",\"so\",\"some\",\"still\",\"such\",\"seeing\", \"see\", \"take\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\n",
    "\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"up\",\"use\",\"using\",\"used\", \"underway\", \"very\",\"want\",\"was\",\"way\",\"we\",\"well\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"whilst\",\"who\",\"will\",\"with\",\"would\",\"you\",\"your\", \n",
    "'etc', 'via', 'eg']) \n",
    "\n",
    "# remove stopwords\n",
    "\n",
    "df[1] = df[1].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovation in Database Management: Computer Sc...</td>\n",
       "      <td>[innovation, database, management, computer, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High performance prime field multiplication fo...</td>\n",
       "      <td>[high, performance, prime, field, multiplicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enchanted scissors: a scissor interface for su...</td>\n",
       "      <td>[enchanted, scissors, scissor, interface, supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detection of channel degradation attack by Int...</td>\n",
       "      <td>[detection, channel, degradation, attack, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pinning a Complex Network through the Betweenn...</td>\n",
       "      <td>[pinning, complex, network, betweenness, centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analysis and Design of Memoryless Interconnect...</td>\n",
       "      <td>[analysis, design, memoryless, interconnect, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dynamic bluescreens.</td>\n",
       "      <td>[dynamic, bluescreens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Quantitative Assured Forwarding Service.</td>\n",
       "      <td>[quantitative, assured, forwarding, service]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automatic sanitization of social network data ...</td>\n",
       "      <td>[automatic, sanitization, social, network, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A &amp;#916;&amp;#931; IR-UWB radar with sub-mm rangin...</td>\n",
       "      <td>[916, 931, ir, uwb, radar, sub, mm, ranging, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Innovation in Database Management: Computer Sc...   \n",
       "1  High performance prime field multiplication fo...   \n",
       "2  enchanted scissors: a scissor interface for su...   \n",
       "3  Detection of channel degradation attack by Int...   \n",
       "4  Pinning a Complex Network through the Betweenn...   \n",
       "5  Analysis and Design of Memoryless Interconnect...   \n",
       "6                               Dynamic bluescreens.   \n",
       "7         A Quantitative Assured Forwarding Service.   \n",
       "8  Automatic sanitization of social network data ...   \n",
       "9  A &#916;&#931; IR-UWB radar with sub-mm rangin...   \n",
       "\n",
       "                                                   1  \n",
       "0  [innovation, database, management, computer, s...  \n",
       "1  [high, performance, prime, field, multiplicati...  \n",
       "2  [enchanted, scissors, scissor, interface, supp...  \n",
       "3  [detection, channel, degradation, attack, inte...  \n",
       "4  [pinning, complex, network, betweenness, centr...  \n",
       "5  [analysis, design, memoryless, interconnect, e...  \n",
       "6                             [dynamic, bluescreens]  \n",
       "7       [quantitative, assured, forwarding, service]  \n",
       "8  [automatic, sanitization, social, network, dat...  \n",
       "9  [916, 931, ir, uwb, radar, sub, mm, ranging, c...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initiate nltk lemmatiser\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# lemmatise words\n",
    "\n",
    "df[1] = df[1].apply(lambda x: [wordnet_lemmatizer.lemmatize(y) for y in x]) \n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8018)\t1\n",
      "  (0, 4092)\t1\n",
      "  (0, 9224)\t1\n",
      "  (0, 3321)\t1\n",
      "  (0, 13901)\t1\n",
      "  (0, 5656)\t1\n",
      "  (0, 8020)\t1\n",
      "  (0, 4112)\t1\n",
      "  (0, 9227)\t1\n",
      "  (0, 3329)\t1\n",
      "  (0, 13903)\t1\n",
      "  (1, 7361)\t1\n",
      "  (1, 11595)\t1\n",
      "  (1, 12200)\t1\n",
      "  (1, 6240)\t1\n",
      "  (1, 10331)\t1\n",
      "  (1, 7062)\t1\n",
      "  (1, 7380)\t1\n",
      "  (1, 11621)\t1\n",
      "  (1, 12201)\t1\n",
      "  (1, 6247)\t1\n",
      "  (1, 10333)\t1\n",
      "  (2, 5582)\t1\n",
      "  (2, 13911)\t1\n",
      "  (2, 13909)\t1\n",
      "  :\t:\n",
      "  (2504, 4458)\t1\n",
      "  (2504, 16160)\t1\n",
      "  (2504, 4108)\t1\n",
      "  (2504, 6052)\t1\n",
      "  (2504, 6053)\t1\n",
      "  (2504, 8196)\t1\n",
      "  (2504, 4555)\t1\n",
      "  (2505, 6660)\t1\n",
      "  (2505, 2608)\t1\n",
      "  (2505, 16288)\t1\n",
      "  (2505, 13932)\t1\n",
      "  (2505, 10991)\t1\n",
      "  (2505, 1308)\t1\n",
      "  (2505, 2609)\t1\n",
      "  (2505, 10853)\t1\n",
      "  (2505, 16293)\t1\n",
      "  (2505, 10855)\t1\n",
      "  (2505, 13935)\t1\n",
      "  (2505, 10992)\t1\n",
      "  (2505, 6664)\t1\n",
      "  (2506, 12878)\t1\n",
      "  (2506, 16264)\t1\n",
      "  (2506, 4699)\t1\n",
      "  (2506, 16267)\t1\n",
      "  (2506, 12880)\t1\n"
     ]
    }
   ],
   "source": [
    "# initialise the count vectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word', ngram_range = (1, 2))\n",
    "                            \n",
    "# join the processed data to be vectorised\n",
    "\n",
    "vectors = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    vectors.append(\", \".join(row[1]))\n",
    "\n",
    "vectorised = vectorizer.fit_transform(vectors)\n",
    "\n",
    "print(vectorised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>Topic10</th>\n",
       "      <th>Dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovation in Database Management: Computer Sc...</td>\n",
       "      <td>[innovation, database, management, computer, s...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High performance prime field multiplication fo...</td>\n",
       "      <td>[high, performance, prime, field, multiplicati...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enchanted scissors: a scissor interface for su...</td>\n",
       "      <td>[enchanted, scissors, scissor, interface, supp...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detection of channel degradation attack by Int...</td>\n",
       "      <td>[detection, channel, degradation, attack, inte...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pinning a Complex Network through the Betweenn...</td>\n",
       "      <td>[pinning, complex, network, betweenness, centr...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analysis and Design of Memoryless Interconnect...</td>\n",
       "      <td>[analysis, design, memoryless, interconnect, e...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dynamic bluescreens.</td>\n",
       "      <td>[dynamic, bluescreens]</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Quantitative Assured Forwarding Service.</td>\n",
       "      <td>[quantitative, assured, forwarding, service]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automatic sanitization of social network data ...</td>\n",
       "      <td>[automatic, sanitization, social, network, dat...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A &amp;#916;&amp;#931; IR-UWB radar with sub-mm rangin...</td>\n",
       "      <td>[916, 931, ir, uwb, radar, sub, mm, ranging, c...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Innovation in Database Management: Computer Sc...   \n",
       "1  High performance prime field multiplication fo...   \n",
       "2  enchanted scissors: a scissor interface for su...   \n",
       "3  Detection of channel degradation attack by Int...   \n",
       "4  Pinning a Complex Network through the Betweenn...   \n",
       "5  Analysis and Design of Memoryless Interconnect...   \n",
       "6                               Dynamic bluescreens.   \n",
       "7         A Quantitative Assured Forwarding Service.   \n",
       "8  Automatic sanitization of social network data ...   \n",
       "9  A &#916;&#931; IR-UWB radar with sub-mm rangin...   \n",
       "\n",
       "                                                   1  Topic1  Topic2  Topic3  \\\n",
       "0  [innovation, database, management, computer, s...    0.92    0.01    0.01   \n",
       "1  [high, performance, prime, field, multiplicati...    0.01    0.01    0.01   \n",
       "2  [enchanted, scissors, scissor, interface, supp...    0.01    0.94    0.01   \n",
       "3  [detection, channel, degradation, attack, inte...    0.01    0.01    0.01   \n",
       "4  [pinning, complex, network, betweenness, centr...    0.01    0.01    0.01   \n",
       "5  [analysis, design, memoryless, interconnect, e...    0.01    0.01    0.01   \n",
       "6                             [dynamic, bluescreens]    0.03    0.77    0.03   \n",
       "7       [quantitative, assured, forwarding, service]    0.01    0.01    0.01   \n",
       "8  [automatic, sanitization, social, network, dat...    0.01    0.01    0.01   \n",
       "9  [916, 931, ir, uwb, radar, sub, mm, ranging, c...    0.00    0.00    0.00   \n",
       "\n",
       "   Topic4  Topic5  Topic6  Topic7  Topic8  Topic9  Topic10  Dominant_topic  \n",
       "0    0.01    0.01    0.01    0.01    0.01    0.01     0.01               1  \n",
       "1    0.01    0.01    0.01    0.01    0.92    0.01     0.01               8  \n",
       "2    0.01    0.01    0.01    0.01    0.01    0.01     0.01               2  \n",
       "3    0.94    0.01    0.01    0.01    0.01    0.01     0.01               4  \n",
       "4    0.01    0.01    0.92    0.01    0.01    0.01     0.01               6  \n",
       "5    0.92    0.01    0.01    0.01    0.01    0.01     0.01               4  \n",
       "6    0.03    0.03    0.03    0.03    0.03    0.03     0.03               2  \n",
       "7    0.01    0.89    0.01    0.01    0.01    0.01     0.01               5  \n",
       "8    0.01    0.01    0.01    0.94    0.01    0.01     0.01               7  \n",
       "9    0.00    0.00    0.00    0.97    0.00    0.00     0.00               7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initisalise LDA Model\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components = 10, # number of topics\n",
    "                                  random_state = 10,          # random state\n",
    "                                  evaluate_every = -1,      # compute perplexity every n iters, default: Don't\n",
    "                                  n_jobs = -1,              # Use all available CPUs\n",
    "                                 )\n",
    "\n",
    "lda_output = lda_model.fit_transform(vectorised)\n",
    "\n",
    "# column names\n",
    "\n",
    "topic_names = [\"Topic\" + str(i) for i in range(1, lda_model.n_components + 1)]\n",
    "\n",
    "# make the pandas dataframe\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns = topic_names)\n",
    "\n",
    "# get dominant topic for each document\n",
    "\n",
    "dominant_topic = (np.argmax(df_document_topic.values, axis=1)+1)\n",
    "df_document_topic['Dominant_topic'] = dominant_topic\n",
    "\n",
    "# join to original dataframes\n",
    "\n",
    "df = pd.merge(df, df_document_topic, left_index = True, right_index = True, how = 'outer')\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['based' 'web' 'network' 'data' 'efficient' 'system' 'design' 'power'\n",
      " 'converter' 'video' 'filter' 'semantic' 'application' 'query' 'analysis'\n",
      " 'database' 'low' 'model' 'control' 'high']\n",
      "['network' 'data' 'based' 'system' 'analysis' 'high' 'power' 'search'\n",
      " 'dynamic' 'wireless' 'aware' 'voltage' 'low' 'level' 'time' 'current'\n",
      " 'linear' 'mode' 'approach' 'algorithm']\n",
      "['network' 'based' 'design' 'application' 'model' 'wireless' 'search'\n",
      " 'efficient' 'multi' 'video' 'time' 'sensor' 'data' 'architecture'\n",
      " 'analysis' 'coding' 'high' 'query' 'cmos' 'web']\n",
      "['network' 'ad' 'hoc' 'ad hoc' 'hoc network' 'data' 'based' 'algorithm'\n",
      " 'wireless' 'system' 'design' 'multi' 'analysis' 'query' 'low' 'routing'\n",
      " 'multiple' 'sensor' 'control' 'bit']\n",
      "['peer' 'network' 'web' 'low' 'database' 'based' 'peer peer' 'model'\n",
      " 'approach' 'search' 'power' 'design' 'system' 'wireless' 'multi'\n",
      " 'sharing' 'time' 'data' '3d' 'mobile']\n",
      "['network' 'low' 'system' 'design' 'query' 'based' 'power' 'web'\n",
      " 'low power' 'algorithm' 'wireless' 'cmos' 'sensor' 'filter' 'voltage'\n",
      " 'fast' 'digital' 'circuit' 'database' 'application']\n",
      "['based' 'system' 'data' 'algorithm' 'design' 'power' 'base' 'data base'\n",
      " 'image' 'time' 'sigma' 'delta' 'web' 'model' 'sigma delta'\n",
      " 'continuous time' 'continuous' 'processing' 'network' 'analysis']\n",
      "['data' 'based' 'web' 'system' 'network' 'large' 'scale' 'large scale'\n",
      " 'design' 'high' 'wireless' 'information' 'time' 'service' 'database'\n",
      " 'synthesis' 'content' 'modeling' 'low' 'multi']\n",
      "['network' 'based' 'multi' 'efficient' 'system' 'control' 'wireless'\n",
      " 'architecture' 'web' 'database' 'model' 'new' 'query' 'algorithm'\n",
      " 'wireless network' 'performance' 'design' 'application' 'hop' 'multi hop']\n",
      "['network' 'based' 'application' 'sensor' 'system' 'analysis' 'time'\n",
      " 'data' 'architecture' 'multi' 'design' 'framework' 'wireless'\n",
      " 'sensor network' 'routing' 'detection' 'query' 'measurement' 'image'\n",
      " 'web']\n"
     ]
    }
   ],
   "source": [
    "keywords = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "topic_keywords = []\n",
    "\n",
    "for topic_weights in lda_model.components_:\n",
    "    top_keyword_locs = (-topic_weights).argsort()[:20]\n",
    "    topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "\n",
    "for i in topic_keywords:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['converter', 'semantic']\n",
      "['dynamic', 'aware', 'level', 'current', 'linear', 'mode']\n",
      "['coding']\n",
      "['ad', 'hoc', 'ad hoc', 'hoc network', 'multiple', 'bit']\n",
      "['peer', 'peer peer', 'sharing', '3d', 'mobile']\n",
      "['low power', 'fast', 'digital', 'circuit']\n",
      "['base', 'data base', 'sigma', 'delta', 'sigma delta', 'continuous time', 'continuous', 'processing']\n",
      "['large', 'scale', 'large scale', 'information', 'service', 'synthesis', 'content', 'modeling']\n",
      "['new', 'wireless network', 'performance', 'hop', 'multi hop']\n",
      "['framework', 'sensor network', 'detection', 'measurement']\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from the keywords extracted from the topic modelling output. This is because we want to limit the amount of Ideas that go across multiple topics. We want to stick to 1 idea to 1 topic\n",
    "dupes = []\n",
    "\n",
    "for i in topic_keywords:\n",
    "    for j in i:\n",
    "        dupes.append(str(j))\n",
    "\n",
    "dupes = [item for item, count in collections.Counter(dupes).items() if count > 1]\n",
    "\n",
    "topic_keywords_processed = []\n",
    "\n",
    "for i in topic_keywords:\n",
    "    tmp = []\n",
    "    for j in i:\n",
    "        if str(j) not in dupes:\n",
    "            tmp.append(str(j))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    topic_keywords_processed.append(tmp)\n",
    "    \n",
    "for i in topic_keywords_processed:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>Topic10</th>\n",
       "      <th>Dominant_topic</th>\n",
       "      <th>Topic_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Innovation in Database Management: Computer Sc...</td>\n",
       "      <td>[innovation, database, management, computer, s...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>[converter, semantic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SocialSensor: sensing user generated input for...</td>\n",
       "      <td>[socialsensor, sensing, user, generated, input...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>[converter, semantic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Estimating clustering coefficients and size of...</td>\n",
       "      <td>[estimating, clustering, coefficient, size, so...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>[converter, semantic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maximum likelihood disjunctive decomposition t...</td>\n",
       "      <td>[maximum, likelihood, disjunctive, decompositi...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>[converter, semantic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intelligent ad resizing.</td>\n",
       "      <td>[intelligent, ad, resizing]</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>[converter, semantic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>Verifying Computations with Streaming Interact...</td>\n",
       "      <td>[verifying, computation, streaming, interactiv...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>[coding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>Efficient bump mapping hardware.</td>\n",
       "      <td>[efficient, bump, mapping, hardware]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>[coding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>Interference analysis on Resonant Inductive Co...</td>\n",
       "      <td>[interference, analysis, resonant, inductive, ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>[coding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>Failure Control in Multipath Route Tracing.</td>\n",
       "      <td>[failure, control, multipath, route, tracing]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>[coding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>A Switched Capacitor Implementation of the Gen...</td>\n",
       "      <td>[switched, capacitor, implementation, generali...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>[coding]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2507 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     Innovation in Database Management: Computer Sc...   \n",
       "1     SocialSensor: sensing user generated input for...   \n",
       "2     Estimating clustering coefficients and size of...   \n",
       "3     Maximum likelihood disjunctive decomposition t...   \n",
       "4                              Intelligent ad resizing.   \n",
       "...                                                 ...   \n",
       "2502  Verifying Computations with Streaming Interact...   \n",
       "2503                   Efficient bump mapping hardware.   \n",
       "2504  Interference analysis on Resonant Inductive Co...   \n",
       "2505        Failure Control in Multipath Route Tracing.   \n",
       "2506  A Switched Capacitor Implementation of the Gen...   \n",
       "\n",
       "                                                      1  Topic1  Topic2  \\\n",
       "0     [innovation, database, management, computer, s...    0.92    0.01   \n",
       "1     [socialsensor, sensing, user, generated, input...    0.95    0.01   \n",
       "2     [estimating, clustering, coefficient, size, so...    0.94    0.01   \n",
       "3     [maximum, likelihood, disjunctive, decompositi...    0.95    0.01   \n",
       "4                           [intelligent, ad, resizing]    0.67    0.02   \n",
       "...                                                 ...     ...     ...   \n",
       "2502  [verifying, computation, streaming, interactiv...    0.01    0.01   \n",
       "2503               [efficient, bump, mapping, hardware]    0.01    0.01   \n",
       "2504  [interference, analysis, resonant, inductive, ...    0.01    0.01   \n",
       "2505      [failure, control, multipath, route, tracing]    0.01    0.01   \n",
       "2506  [switched, capacitor, implementation, generali...    0.01    0.01   \n",
       "\n",
       "      Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  Topic9  Topic10  \\\n",
       "0       0.01    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "1       0.01    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "2       0.01    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "3       0.01    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "4       0.02    0.20    0.02    0.02    0.02    0.02    0.02     0.02   \n",
       "...      ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "2502    0.91    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "2503    0.89    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "2504    0.95    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "2505    0.91    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "2506    0.94    0.01    0.01    0.01    0.01    0.01    0.01     0.01   \n",
       "\n",
       "      Dominant_topic         Topic_keywords  \n",
       "0                  1  [converter, semantic]  \n",
       "1                  1  [converter, semantic]  \n",
       "2                  1  [converter, semantic]  \n",
       "3                  1  [converter, semantic]  \n",
       "4                  1  [converter, semantic]  \n",
       "...              ...                    ...  \n",
       "2502               3               [coding]  \n",
       "2503               3               [coding]  \n",
       "2504               3               [coding]  \n",
       "2505               3               [coding]  \n",
       "2506               3               [coding]  \n",
       "\n",
       "[2507 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords_processed)\n",
    "df_topic_keywords.columns = ['Term '+ str(i) for i in range(1, df_topic_keywords.shape[1] + 1)]\n",
    "df_topic_keywords['Topic_keywords'] = df_topic_keywords.values.tolist()\n",
    "df_topic_keywords['Topic_number'] = df_topic_keywords.index + 1\n",
    "df_topic_keywords = df_topic_keywords[['Topic_keywords', 'Topic_number']]\n",
    "\n",
    "# Remove None from lists\n",
    "tmp = []\n",
    "\n",
    "for i in df_topic_keywords['Topic_keywords']:\n",
    "    tmp.append([x for x in i if x is not None])\n",
    "\n",
    "df_topic_keywords['Topic_keywords'] = tmp\n",
    "\n",
    "# Merge key terms back to main frame\n",
    "df = pd.merge(df, df_topic_keywords, left_on='Dominant_topic', right_on='Topic_number')\n",
    "del df['Topic_number']\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>engineering semantic web information systems /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>digital converter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>boost converter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>dc converters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>voltage converter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>general framework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>market framework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>human detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>3.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>end measurement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>14.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>adaptive visual search framework</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     score  topic_number                                               term\n",
       "0     25.0           1.0  engineering semantic web information systems /...\n",
       "18     4.0           1.1                                  digital converter\n",
       "17     4.0           1.1                                    boost converter\n",
       "16     4.5           1.1                                      dc converters\n",
       "15     5.0           1.1                                  voltage converter\n",
       "..     ...           ...                                                ...\n",
       "297    4.0          10.1                                  general framework\n",
       "298    4.0          10.1                                   market framework\n",
       "299    4.0          10.1                                    human detection\n",
       "300    3.5          10.1                                    end measurement\n",
       "282   14.5          10.1                   adaptive visual search framework\n",
       "\n",
       "[316 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for i in df['Dominant_topic'].unique():\n",
    "    topic = df[df['Dominant_topic'] == i]\n",
    "\n",
    "    key_words = []\n",
    "\n",
    "    for j in topic[0].values.tolist():\n",
    "        r = Rake()\n",
    "        a = r.extract_keywords_from_text(j)\n",
    "        c = r.get_ranked_phrases_with_scores()\n",
    "\n",
    "        for k in c:\n",
    "            if k not in key_words:\n",
    "                key_words.append(k)\n",
    "\n",
    "    key_words = pd.DataFrame(key_words, columns =['score', 'term'])  \n",
    "    key_words = key_words.sort_values('score', ascending=False)\n",
    "    key_words['term_list'] = key_words.term.apply(lambda x: x.split())\n",
    "\n",
    "    # find bigrams from key words to match against topic modelling output\n",
    "    tmp_keywords = []\n",
    "\n",
    "    for j in key_words.values.tolist():\n",
    "        tmp = []\n",
    "\n",
    "        bi_grams = ngrams(j[2], 2)\n",
    "        \n",
    "        for g in bi_grams:\n",
    "            tmp.append(' '.join(g))\n",
    "        \n",
    "        for k in j[2]:\n",
    "            tmp.append(k)\n",
    "            # lemmatise words to match the lemmatised output of the topic modelling word extraction\n",
    "            tmp.append(wordnet_lemmatizer.lemmatize(k))\n",
    "            \n",
    "        j.remove(j[2])\n",
    "        j.append(list(set(tmp)))\n",
    "\n",
    "        tmp_keywords.append(j)\n",
    "\n",
    "    key_words = pd.DataFrame(tmp_keywords, columns =['score', 'term', 'term_list'])  \n",
    "\n",
    "    topic_keywords = topic['Topic_keywords'].values.tolist()\n",
    "    topic_keywords = [item for sublist in topic_keywords for item in sublist]\n",
    "    topic_keywords = list(set(topic_keywords))\n",
    "    \n",
    "    tmp = []\n",
    "\n",
    "    for t in topic_keywords:\n",
    "        mask = key_words.term_list.apply(lambda x: t in x)\n",
    "        key_words_processed = key_words[mask]\n",
    "\n",
    "        if key_words_processed.empty:\n",
    "            pass\n",
    "        else:\n",
    "            for j in key_words_processed[['score', 'term']].values.tolist():\n",
    "                if j not in tmp:\n",
    "                    tmp.append(j)\n",
    "    \n",
    "    # get the keywords for the optimal number of topics\n",
    "    key_words = pd.DataFrame(tmp, columns =['score', 'term'])  \n",
    "    key_words = key_words.sort_values('score', ascending=False)\n",
    "    key_words = key_words.drop_duplicates(subset=['term'])\n",
    "    key_words['topic_number'] = i\n",
    "    \n",
    "    # select the max score as the topic title\n",
    "    top_key_words = key_words[key_words.score == key_words['score'].max()]\n",
    "\n",
    "    # select the remaining keywords as child terms. \n",
    "    remaining_keywords = key_words[key_words.score != key_words['score'].max()]\n",
    "    \n",
    "    # if there are more than 1 keyword in the topic title, aggregate them with a / as a separatore\n",
    "    top_key_words = top_key_words.copy()\n",
    "    top_key_words = top_key_words.groupby(['score', 'topic_number']).agg({'term' : lambda x: ' / '.join(map(str, x))})\n",
    "    top_key_words = top_key_words.reset_index()\n",
    "\n",
    "    # add 0.1 to the child keywords to identify then in the merged dataframe\n",
    "    remaining_keywords = remaining_keywords.copy()\n",
    "    remaining_keywords['topic_number'] = remaining_keywords['topic_number'] + 0.1\n",
    "\n",
    "    all_topics = pd.concat([top_key_words, remaining_keywords], sort=False)\n",
    "    \n",
    "    for t in all_topics.to_dict(orient='records'):\n",
    "        all_results.append(t)\n",
    "\n",
    "all_topics_df = pd.DataFrame(all_results)\n",
    "all_topics_df = all_topics_df.sort_values('topic_number', ascending=True)\n",
    "all_topics_df = all_topics_df.loc[all_topics_df['score'] > 1.0]\n",
    "\n",
    "display(all_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
